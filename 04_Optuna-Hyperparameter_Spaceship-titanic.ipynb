{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter 최적화: Spaceship Titanic\n",
    "#### 작성: 고우주 | kubwa 쿱와"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 불러오기 & 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/spaceship-preprocessing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Transported'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(df.corr('pearson'), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Transported' , axis =1 )\n",
    "y = df['Transported']\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , \n",
    "                                                       y, \n",
    "                                                       random_state = 100,\n",
    "                                                       test_size =0.2)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Standardize Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Parameter tuning `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 주요 Hyper-parameter\n",
    "- max_depth: 개별 나무의 깊이 (나무를 대충하기 위해 작은값)\n",
    "- learning_rate: Boosting 단계 별로 가중치를 두는 학습율\n",
    "- n_estimators: 나무의 수\n",
    "- subsample: 각 나무를 학습할 때 사용하는 포인트 수의 비율 (0 초과 1 이하의 숫자로 비율 설정)\n",
    "- colsample_bytree: 각 나무에서 사용하는 features 수의 비율 (0 초과 1 이하의 숫자로 비율 설정)\n",
    "- gamma: 각 나무에서 분할하는데 필요한 최소 손실감소량\n",
    "- reg_lambda: 각 나무에 배정되는 weights에 대하여 L2-regularization 강도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna \n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Define the objective function\"\"\"\n",
    "\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'use_label_encoder': False\n",
    "    }\n",
    "\n",
    "    # Fit the model\n",
    "    xgb_model = XGBClassifier(**params)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(trial.value))\n",
    "print('  Params: ')\n",
    "\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 시각화\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 파라미터들관의 관계\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 각 파라미터들의 상관관계\n",
    "optuna.visualization.plot_contour(\n",
    "    study,\n",
    "    params=[\n",
    "        \"max_depth\",\n",
    "        \"learning_rate\",\n",
    "        \"n_estimators\",\n",
    "        \"subsample\",\n",
    "        \"reg_lambda\",\n",
    "        \"colsample_bytree\",\n",
    "        \"gamma\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 중요도\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
